{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LCmXmpB_xxpM8IC-J50tLC3058IIpsDa","timestamp":1738680507060}],"gpuType":"T4","mount_file_id":"1LCmXmpB_xxpM8IC-J50tLC3058IIpsDa","authorship_tag":"ABX9TyM7W/eXHWze3+KHLYSx4/JH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ohkfjq5mnbZv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738677821442,"user_tz":-180,"elapsed":1383030,"user":{"displayName":"Duygu Halisyama","userId":"12172883560973896061"}},"outputId":"32840dc7-1e42-4f66-d2ca-146134f81762"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 18ms/step - loss: 0.0357 - val_loss: 0.0080 - learning_rate: 0.0010\n","Epoch 2/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 16ms/step - loss: 0.0034 - val_loss: 0.0018 - learning_rate: 0.0010\n","Epoch 3/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 0.0024 - val_loss: 0.0034 - learning_rate: 0.0010\n","Epoch 4/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0017 - val_loss: 0.0013 - learning_rate: 0.0010\n","Epoch 5/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0012 - learning_rate: 0.0010\n","Epoch 6/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 9.7883e-04 - learning_rate: 0.0010\n","Epoch 7/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0010 - val_loss: 7.8705e-04 - learning_rate: 0.0010\n","Epoch 8/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 8.4684e-04 - val_loss: 9.4774e-04 - learning_rate: 0.0010\n","Epoch 9/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 7.6974e-04 - val_loss: 9.2349e-04 - learning_rate: 0.0010\n","Epoch 10/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 6.4456e-04 - val_loss: 7.3811e-04 - learning_rate: 0.0010\n","Epoch 11/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 5.7596e-04 - val_loss: 8.1351e-04 - learning_rate: 0.0010\n","Epoch 12/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 5.5807e-04 - val_loss: 7.3146e-04 - learning_rate: 0.0010\n","Epoch 13/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 3.9336e-04 - val_loss: 4.3346e-04 - learning_rate: 5.0000e-04\n","Epoch 14/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 3.6496e-04 - val_loss: 6.2034e-04 - learning_rate: 5.0000e-04\n","Epoch 15/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 3.2722e-04 - val_loss: 4.4551e-04 - learning_rate: 5.0000e-04\n","Epoch 16/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 2.9614e-04 - val_loss: 6.3896e-04 - learning_rate: 5.0000e-04\n","Epoch 17/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - loss: 3.2676e-04 - val_loss: 5.9408e-04 - learning_rate: 5.0000e-04\n","Epoch 18/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - loss: 2.7979e-04 - val_loss: 4.2063e-04 - learning_rate: 5.0000e-04\n","Epoch 19/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 2.2869e-04 - val_loss: 3.5068e-04 - learning_rate: 2.5000e-04\n","Epoch 20/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - loss: 2.1107e-04 - val_loss: 3.8084e-04 - learning_rate: 2.5000e-04\n","Epoch 21/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - loss: 2.1969e-04 - val_loss: 3.1882e-04 - learning_rate: 2.5000e-04\n","Epoch 22/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - loss: 2.0128e-04 - val_loss: 3.5204e-04 - learning_rate: 2.5000e-04\n","Epoch 23/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - loss: 1.9353e-04 - val_loss: 3.4997e-04 - learning_rate: 2.5000e-04\n","Epoch 24/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - loss: 1.9062e-04 - val_loss: 3.2402e-04 - learning_rate: 2.5000e-04\n","Epoch 25/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - loss: 1.9078e-04 - val_loss: 3.2448e-04 - learning_rate: 2.5000e-04\n","Epoch 26/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - loss: 1.8327e-04 - val_loss: 3.0753e-04 - learning_rate: 2.5000e-04\n","Epoch 27/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - loss: 1.6314e-04 - val_loss: 2.9595e-04 - learning_rate: 1.2500e-04\n","Epoch 28/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - loss: 1.7290e-04 - val_loss: 2.7994e-04 - learning_rate: 1.2500e-04\n","Epoch 29/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - loss: 1.5878e-04 - val_loss: 2.7063e-04 - learning_rate: 1.2500e-04\n","Epoch 30/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - loss: 1.5808e-04 - val_loss: 2.9962e-04 - learning_rate: 1.2500e-04\n","Epoch 31/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - loss: 1.5637e-04 - val_loss: 2.8873e-04 - learning_rate: 1.2500e-04\n","Epoch 32/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 1.4543e-04 - val_loss: 2.5988e-04 - learning_rate: 6.2500e-05\n","Epoch 33/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - loss: 1.4503e-04 - val_loss: 2.5151e-04 - learning_rate: 6.2500e-05\n","Epoch 34/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 1.4112e-04 - val_loss: 2.9730e-04 - learning_rate: 6.2500e-05\n","Epoch 35/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - loss: 1.4575e-04 - val_loss: 2.6420e-04 - learning_rate: 6.2500e-05\n","Epoch 36/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - loss: 1.3962e-04 - val_loss: 2.8494e-04 - learning_rate: 6.2500e-05\n","Epoch 37/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 1.3691e-04 - val_loss: 2.5900e-04 - learning_rate: 3.1250e-05\n","Epoch 38/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 1.3153e-04 - val_loss: 2.6269e-04 - learning_rate: 3.1250e-05\n","Epoch 39/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - loss: 1.3433e-04 - val_loss: 2.7986e-04 - learning_rate: 3.1250e-05\n","Epoch 40/100\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - loss: 1.3268e-04 - val_loss: 2.6792e-04 - learning_rate: 3.1250e-05\n","LSTM Forecast saved to /content/drive/MyDrive/Colab Notebooks/visea/forecast_lstm_results_model2_seq24.xlsx\n","(39460, 24, 1)  X_train\n","(4388, 24, 1) X_val\n","\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n","Validation R²: 0.9915\n","Validation RMSE: 31.8277\n","Validation MAPE: 0.0125\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Veriyi okuma\n","file_path = \"/content/drive/MyDrive/Colab Notebooks/visea/train2.xlsx\"\n","data = pd.read_excel(file_path)\n","\n","data['DateTime'] = pd.to_datetime(data['DateTime'])\n","data.set_index('DateTime', inplace=True)\n","\n","# Veriyi ölçeklendirme\n","scaler = MinMaxScaler()\n","data_scaled = scaler.fit_transform(data[['Distributed Energy']])\n","\n","# Zaman serisi verisini LSTM için uygun hale getirme\n","def create_sequences(data, seq_length):\n","    sequences = []\n","    labels = []\n","    for i in range(len(data) - seq_length):\n","        sequences.append(data[i:i+seq_length])\n","        labels.append(data[i+seq_length])\n","    return np.array(sequences), np.array(labels)\n","\n","\n","# Son 24 saatlik veriyi kullanarak tahmin yap\n","seq_length = 24\n","train_size = int(len(data_scaled) * 0.9)\n","train_data = data_scaled[:train_size]\n","val_data = data_scaled[train_size - seq_length:]  # Geçmiş bilgiyi de içermeli\n","\n","X_train, y_train = create_sequences(train_data, seq_length)\n","X_val, y_val = create_sequences(val_data, seq_length)\n","\n","# Model Tanımlama\n","model = Sequential([\n","    Input(shape=(seq_length, 1)),\n","    Bidirectional(LSTM(100, return_sequences=True)),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","    Bidirectional(LSTM(100, return_sequences=True)),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","    LSTM(50, return_sequences=False),\n","    BatchNormalization(),\n","    Dense(50, activation='relu'),\n","    Dense(25, activation='relu'),\n","    Dense(1)\n","])\n","\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n","\n","# Early Stopping ve Learning Rate Reduction\n","early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n","\n","epochs = 100\n","batch_size = 32\n","model.fit(X_train, y_train,\n","          validation_data=(X_val, y_val),\n","          epochs=epochs,\n","          batch_size=batch_size,\n","          callbacks=[early_stopping, reduce_lr])\n","\n","\n","\n"]},{"cell_type":"code","source":["# Son 24 saatlik veriyi alarak 48 saat tahmin yapma\n","forecast_input = data_scaled[-seq_length:].reshape(1, seq_length, 1)\n","forecast = []\n","\n","for _ in range(48):  # 48 saatlik tahmin\n","    next_hour = model.predict(forecast_input, verbose=0)\n","    forecast.append(next_hour[0, 0])\n","    forecast_input = np.append(forecast_input[:, 1:, :], next_hour.reshape(1, 1, 1), axis=1)\n","\n","# Tahminleri ters ölçeklendirme\n","forecast_rescaled = scaler.inverse_transform(np.array(forecast).reshape(-1, 1))\n","\n","# Sonuçları kaydetme\n","forecast_dates = pd.date_range(start=data.index[-1], periods=49, freq='h')[1:]  # Tahmin tarihleri\n","forecast_df = pd.DataFrame({'DateTime': forecast_dates, 'Forecasted Value': forecast_rescaled.flatten()})\n","output_file = \"/content/drive/MyDrive/Colab Notebooks/visea/forecast_lstm_results_model2_seq24.xlsx\"\n","forecast_df.to_excel(output_file, index=False)\n","\n","# Tahmin sonuçlarını değerlendirme\n","print(f\"LSTM Forecast saved to {output_file}\")\n","\n","# Modeli kaydetme\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/visea/lstm_forecast_model2_seq24.keras\")\n","print(X_train.shape, \" X_train\")\n","print(X_val.shape, \"X_val\")\n","\n","from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n","\n","# Tahminler yapılır\n","y_val_pred = model.predict(X_val)\n","# Tahminlerinizi ve gerçek değerlerinizi scaler ile tersine çevirebilirsiniz\n","y_val_pred_inverse = scaler.inverse_transform(y_val_pred.reshape(-1, 1))\n","y_val_inverse = scaler.inverse_transform(y_val.reshape(-1, 1))\n","\n","# Hata metriklerinizi tekrar hesaplayın\n","r2 = r2_score(y_val_inverse, y_val_pred_inverse)\n","print(f\"Validation R²: {r2:.4f}\")\n","\n","rmse = np.sqrt(mean_squared_error(y_val_inverse, y_val_pred_inverse))\n","print(f\"Validation RMSE: {rmse:.4f}\")\n","\n","mape = mean_absolute_percentage_error(y_val_inverse, y_val_pred_inverse)\n","print(f\"Validation MAPE: {mape:.4f}\")"],"metadata":{"id":"SX9002yEai7C"},"execution_count":null,"outputs":[]}]}