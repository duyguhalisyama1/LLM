{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LCmXmpB_xxpM8IC-J50tLC3058IIpsDa",
      "authorship_tag": "ABX9TyMZUFHEBvBc6D1H9DfwstSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duyguhalisyama1/LLM/blob/main/pdf_embeddings_table_llm_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohkfjq5mnbZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95df4b30-5070-4225-b9e5-a2e99d95d0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ PDF i√ßeriƒüi i≈üleniyor...\n",
            "üîç Tablo √∂ƒüeleri baƒülamsal olarak zenginle≈ütiriliyor...\n",
            "üìå Pinecone index ba≈ülatƒ±lƒ±yor...\n",
            "üîó Embedding'ler olu≈üturuluyor ve Pinecone'a g√∂nderiliyor...\n",
            "üìå 14 i√ßerik Pinecone'a y√ºklendi.\n",
            "Average Rectified Forward Current: 150 mA\n",
            "Cathode Polarity: Not Available\n",
            "Configuration: Not Available\n",
            "Material: Not Available\n",
            "Maximum Continuous Forward Current: 250 mA\n",
            "Maximum DC Reverse Voltage: 70 V\n",
            "Maximum Diode Capacitance: 1.5 pF\n",
            "Maximum Junction Ambient Thermal Resistance: 430 K/W\n",
            "Maximum Junction Case Thermal Resistance: 430 K/W\n",
            "Maximum Operating Temperature: +150 ¬∞C\n",
            "Maximum Power Dissipation: 300 mW\n",
            "Maximum RMS Reverse Voltage: Not Available\n",
            "Maximum Storage Temperature: +150 ¬∞C\n",
            "Minimum Operating Temperature: -55 ¬∞C\n",
            "Minimum Storage Temperature: -55\n",
            "Operating Junction Temperature: -55...+150¬∞C\n",
            "Peak Forward Voltage: Not Available\n",
            "Peak Non-Repetitive Surge Current: 1 A\n",
            "Peak Reverse Current: 2.5 ŒºA\n",
            "Peak Reverse Recovery Time: 6 ns\n",
            "Peak Reverse Repetitive Voltage: Not Available\n",
            "Process Technology: Not Available\n",
            "Repetitive Peak Forward Current: Not Available\n",
            "Speed: Not Available\n",
            "Supplier Temperature Grade: Not Available\n",
            "Tradename: BAV99\n",
            "Type: Not Available\n",
            "Typical Junction Capacitance: Not Available\n",
            "Typical Reverse Recovery Charge: Not Available\n",
            "üßπ Pinecone temizleniyor...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import (\n",
        "    Pinecone, ServerlessSpec, CloudProvider, AwsRegion, Metric, VectorType\n",
        ")\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "from groq import Groq\n",
        "import fitz, pymupdf\n",
        "\n",
        "import os\n",
        "import certifi\n",
        "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
        "\n",
        "\n",
        "# API Anahtarlarƒ±\n",
        "load_dotenv()\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
        "\n",
        "# Model ve istemciler\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "embedding_model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v2-moe\", trust_remote_code=True)\n",
        "\n",
        "# üì• PDF'den t√ºm metni √ßek\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pymupdf.open(pdf_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# üìä Tablo a√ßƒ±klamasƒ± + markdown formatƒ± √ºret\n",
        "def enrich_table_with_context(table_content, document_context):\n",
        "    prompt = f\"\"\"\n",
        "    Given the following table and its context from the original document,\n",
        "    provide a detailed description of the table. Then, include the table in markdown format.\n",
        "\n",
        "    Original Document Context:\n",
        "    {document_context}\n",
        "\n",
        "    Table Content:\n",
        "    {table_content}\n",
        "\n",
        "    Please provide:\n",
        "    1. A comprehensive description of the table.\n",
        "    2. The table in markdown format.\n",
        "    \"\"\"\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that describes tables and formats them in markdown.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        model=\"llama3-70b-8192\"\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "# üß† Metni embedding'e d√∂n√º≈üt√ºr\n",
        "def get_embedding(text):\n",
        "    return embedding_model.encode(text).tolist()\n",
        "\n",
        "# üß± Pinecone index ba≈ülat\n",
        "def init_pinecone(index_name, dimension=768):\n",
        "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "    indexes = pc.list_indexes()  # Mevcut index'leri alƒ±r\n",
        "\n",
        "    # Eƒüer index mevcutsa, doƒürudan mevcut index'e baƒülan\n",
        "    if index_name in indexes:\n",
        "        print(f\"üîç Var olan Pinecone index'e baƒülanƒ±lƒ±yor: {index_name}\")\n",
        "        return pc.Index(index_name)\n",
        "\n",
        "    try:\n",
        "        # Index yoksa, olu≈üturmayƒ± dene\n",
        "        index_config = pc.create_index(\n",
        "            name=index_name,\n",
        "            dimension=dimension,\n",
        "            metric=Metric.COSINE,  # Vekt√∂r kar≈üƒ±la≈ütƒ±rma metrik olarak COSINE kullanƒ±lƒ±yor\n",
        "            spec=ServerlessSpec(\n",
        "                cloud=CloudProvider.AWS,\n",
        "                region=AwsRegion.US_EAST_1  # ƒ∞htiyacƒ±nƒ±za g√∂re b√∂lgeyi deƒüi≈ütirebilirsiniz\n",
        "            ),\n",
        "            vector_type=VectorType.DENSE\n",
        "        )\n",
        "        print(f\"‚úÖ Yeni Pinecone index olu≈üturuldu: {index_name}\")\n",
        "        return pc.Index(host=index_config.host)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Eƒüer \"ALREADY_EXISTS\" hatasƒ± alƒ±rsak, mevcut index'e baƒülanƒ±yoruz.\n",
        "        if \"ALREADY_EXISTS\" in str(e):\n",
        "            return pc.Index(index_name)\n",
        "        else:\n",
        "            raise e\n",
        "\n",
        "# üì§ Pinecone'a i√ßerikleri g√∂nder\n",
        "def upsert_elements(index, elements):\n",
        "    vectors = []\n",
        "    for i, el in enumerate(elements):\n",
        "        if el.text:\n",
        "            embedding = get_embedding(el.text)\n",
        "            vectors.append((f\"element-{i}\", embedding, {\"content\": el.text}))\n",
        "    index.upsert(vectors=vectors, namespace=\"doc_namespace\")\n",
        "    print(f\"üìå {len(vectors)} i√ßerik Pinecone'a y√ºklendi.\")\n",
        "\n",
        "# üîé Pinecone'dan bilgi al\n",
        "def retrieve(index, query, top_k=3):\n",
        "    query_embedding = get_embedding(query)\n",
        "    res = index.query(\n",
        "        vector=query_embedding,\n",
        "        top_k=top_k,\n",
        "        include_metadata=True,\n",
        "        namespace=\"doc_namespace\"\n",
        "    )\n",
        "    return \"\\n\\n---\\n\\n\".join([match[\"metadata\"][\"content\"] for match in res[\"matches\"]]) if res[\"matches\"] else \"No relevant context found.\"\n",
        "\n",
        "# üß† LLM ile cevap olu≈ütur\n",
        "def complete(prompt):\n",
        "    try:\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "            model=\"llama3-70b-8192\"\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Groq API Error: {str(e)}\"\n",
        "\n",
        "# üöÄ Ana S√ºre√ß\n",
        "def main():\n",
        "    pdf_path = \"/content/LLM/bav99.pdf\"\n",
        "    excel_file = '/content/LLM/Ek-3 Temel √ñznitelik Tanƒ±mlarƒ±.xlsx'\n",
        "    filter_value = 'Rectifiers'\n",
        "    index_name = \"pdf-embeddings-table-context\"\n",
        "\n",
        "    print(\"üìÑ PDF i√ßeriƒüi i≈üleniyor...\")\n",
        "    elements = partition_pdf(\n",
        "        filename=pdf_path,\n",
        "        strategy=\"hi_res\",\n",
        "        chunking_strategy=\"by_title\"\n",
        "    )\n",
        "    document_context = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    print(\"üîç Tablo √∂ƒüeleri baƒülamsal olarak zenginle≈ütiriliyor...\")\n",
        "    for element in elements:\n",
        "        if element.category == 'Table':\n",
        "            table_content = element.text\n",
        "            enriched_text = enrich_table_with_context(table_content, document_context)\n",
        "            element.text = enriched_text\n",
        "\n",
        "    print(\"üìå Pinecone index ba≈ülatƒ±lƒ±yor...\")\n",
        "    index = init_pinecone(index_name)\n",
        "    #index.delete(delete_all=True, namespace=\"doc_namespace\")\n",
        "\n",
        "    print(\"üîó Embedding'ler olu≈üturuluyor ve Pinecone'a g√∂nderiliyor...\")\n",
        "    upsert_elements(index, elements)\n",
        "\n",
        "    # √ñrnek sorgular (Excel'e baƒülƒ± alan tarama)\n",
        "    df = pd.read_excel(excel_file)\n",
        "    fields = df[df.iloc[:, 6] == filter_value].iloc[:, 8].dropna().tolist()\n",
        "\n",
        "    for field in fields:\n",
        "        query_prompt = f\"Find the exact value for: {field} in the datasheet.\"\n",
        "        retrieved_context = retrieve(index, query_prompt)\n",
        "\n",
        "        full_prompt = f\"\"\"\n",
        "        Answer the question based on the context below. Extract ONLY the exact numerical value and unit OR specified term.\n",
        "        If the value is not available in the given context, return \"Not Available\" and nothing else.\n",
        "        Consider synonyms, abbreviations, and variations of the term while searching.\n",
        "\n",
        "        Context:\n",
        "        {retrieved_context}\n",
        "\n",
        "        Question: What is the exact value for {field} (including any synonymous terms or variations)?\n",
        "\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        answer = complete(full_prompt)\n",
        "        print(f\"{field}: {answer}\")\n",
        "\n",
        "    print(\"üßπ Pinecone temizleniyor...\")\n",
        "    #index.delete(delete_all=True, namespace=\"doc_namespace\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tools\n",
        "%pip install dotenv\n",
        "%pip install groq\n",
        "%pip install pandas\n",
        "%pip install pi_heif\n",
        "%pip install unstructured_inference\n",
        "%pip install pdf2image\n",
        "%pip install unstructured_pytesseract\n",
        "%pip install pymupdf\n",
        "%pip install unstructured\n",
        "%pip install pdfminer.six==20221105\n",
        "%pip install PyMuPDF\n",
        "\n",
        "%pip install pinecone\n",
        "!pip install python-dotenv\n",
        "!apt-get install poppler-utils\n",
        "\n"
      ],
      "metadata": {
        "id": "SX9002yEai7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/duyguhalisyama1/LLM.git\n",
        "%cd LLM"
      ],
      "metadata": {
        "id": "AGLZlfk5ICd_",
        "outputId": "6290274f-0b42-44cf-f524-ba3280600014",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLM'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 30 (delta 8), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (30/30), 3.70 MiB | 9.53 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "/content/LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "print(fitz.__file__)\n",
        "print(dir(fitz))  # 'open' ve/veya 'Document' g√∂rmelisin\n"
      ],
      "metadata": {
        "id": "LlErN3ShUX32",
        "outputId": "95438bb6-209c-4c1f-e543-604336a208b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fitz/__init__.py\n",
            "['__author__', '__author_email__', '__builtins__', '__cached__', '__doc__', '__downloadUrl__', '__file__', '__license__', '__loader__', '__maintainer_email__', '__name__', '__package__', '__path__', '__spec__', '__url__', '__version__', 'op', 'tools']\n"
          ]
        }
      ]
    }
  ]
}